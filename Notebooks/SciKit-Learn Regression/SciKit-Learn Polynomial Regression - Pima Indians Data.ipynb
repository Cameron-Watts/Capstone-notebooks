{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression of Blood Glucose Level\n",
    "\n",
    "Data downloaded from Kaggle at https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "\n",
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import packages\n",
    "\n",
    "#Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Finding the data on our system\n",
    "import pathlib\n",
    "\n",
    "#Linear regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Extra SciKit-Learn functions to create a polynomial regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Metrics to evaluate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "#Plotting library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Import data from another directory\n",
    "\n",
    "#Find the file from a local directiory\n",
    "p = str(pathlib.Path().resolve()).replace(\"\\\\Notebooks\\\\SciKit-Learn Regression\", \"\")\n",
    "p += (\"\\\\Data\\\\Raw\\\\Pima_Indians.csv\")\n",
    "p = pathlib.Path(p).resolve()\n",
    "\n",
    "#Read into a pandas dataframe\n",
    "df = pd.read_csv(p)\n",
    "\n",
    "#Preview the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Rows for Test Data\n",
    "\n",
    "A vital part of machine learning is being able to test with data that the model is not trained on. This means that we can test the generalisability of our regression with this data. We use SciKit-Learn's train_test_split in order to take 20% of the data at random to be test data.\n",
    "\n",
    "We also rename the training portions of the data accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"Glucose\"], axis=1)\n",
    "y = df[\"Glucose\"]\n",
    "\n",
    "training_x, test_x, training_y, test_y = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for Multicollinearity\n",
    "\n",
    "For this dataset, we did this in the previous section (Linear regression), so we do not need to do this again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Pipeline\n",
    "\n",
    "As a polynomial regression requires the applying of two functions to our data (PolynomialFeatures to transform it, and Linear regression to fit the weights), we can put these together into a pipeline, which applies both of these to any data added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to define model\n",
    "\n",
    "def PolynomialRegression(degree = 2, interaction_only = False):\n",
    "    \"\"\"\n",
    "    This function returns a model with the desired degree, of the following pipeline\n",
    "    \n",
    "    PolynomialFeatures(degree) --> LinearRegression\n",
    "    \n",
    "    The resulting model can then be applied to the data, to fit a polynomial regression\n",
    "    \"\"\"\n",
    "    \n",
    "    #Define pipeline, first applying PolynomialFeatures, then LinearRegression\n",
    "    model = Pipeline([('PolynomialFeatures', PolynomialFeatures(degree=degree)), \n",
    "                      ('LinearRegression', linear_model.LinearRegression())])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting an Extremely Wiggly Line\n",
    "\n",
    "Something we can do next is to fit a line to our data, with a very high degree of 10. However, this generally isn't the best idea, as demonstrated by the Mean Squared Error (MSE) of this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PolynomialFeatures', PolynomialFeatures(degree=10)),\n",
       "                ('LinearRegression', LinearRegression())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression Object\n",
    "wiggly_reg = PolynomialRegression(degree=10)\n",
    "\n",
    "#Fit the linear regression model with our training data\n",
    "wiggly_reg.fit(training_x, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error:  65.15684745948603\n",
      "Test Mean Squared Error:  978929490239911.5\n"
     ]
    }
   ],
   "source": [
    "##Test the MSE\n",
    "\n",
    "#Predict values using the regression model \n",
    "\n",
    "y_pred = wiggly_reg.predict(training_x)\n",
    "y_test_pred = wiggly_reg.predict(test_x)\n",
    "\n",
    "#Find the MSe\n",
    "print(\"Training Mean Squared Error: \", mean_squared_error(training_y, y_pred))\n",
    "print(\"Test Mean Squared Error: \", mean_squared_error(test_y, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the training MSE is extremely good, the error is really small compared to the value of the average point. However, the test MSE is insanely large. What happened?\n",
    "\n",
    "What we just experienced was overfitting. Although we can make a very accurate line for our training data, such that the line predicts all of the given points well, we can't make it wiggle correctly for the test data, as we can't see it during training. This means that our test data isn't fit at all well, and the model has no generalisability to new points.\n",
    "\n",
    "We need to be careful of overfitting when training a model, because although this is an extreme example, it can be more subtle. To avoid this, don't assign very high degrees to your polynomial regressions, and check your fit metrics. A key indicator of overfitting is when your model performs significantly worse on your test data than your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Regression Model\n",
    "\n",
    "Next, we use the data to train a more sensible polynomial regression model, with degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('PolynomialFeatures', PolynomialFeatures()),\n",
       "                ('LinearRegression', LinearRegression())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Linear Regression Object\n",
    "reg = PolynomialRegression(degree=2)\n",
    "\n",
    "#Fit the linear regression model with our training data\n",
    "reg.fit(training_x, training_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutating Fit of Model\n",
    "\n",
    "To evaluate the fit of the model, we compare predicted values using the model to the true values observed. The test values are an important indicator, as we can see if our model generalises to more data points from the same set, without having to be trained on these.\n",
    "\n",
    "This is done using `model.predict(true_value, predicted_value)`\n",
    "\n",
    "### Mean Squared Error\n",
    "\n",
    "One easy way to evaluate the fit of our model is to look at the Mean Squared Error (MSE) of our model. This can be done for both the training and test data sets.\n",
    "\n",
    "The error here is quite large compared to the value of the glucose. This generally indicates that our predictions still won't be amazing, although depending on the difficulty of prediction, this level of accuracy could be an achievement in itself. Remember that metric values will depend on the exact problem that you are tackling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict values using the regression model \n",
    "\n",
    "y_pred = reg.predict(training_x)\n",
    "y_test_pred = reg.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mean Squared Error:  601.9556131001212\n",
      "Test Mean Squared Error:  741.8029012657818\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Mean Squared Error: \", mean_squared_error(training_y, y_pred))\n",
    "print(\"Test Mean Squared Error: \", mean_squared_error(test_y, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained Variance Score\n",
    "\n",
    "The Explained Variance Score gives a measure of how much of the variance in the dependent variable can be explained by variance in the indepenent variables. A value of 1 would mean that all of the variance can be explained, and can mean a perfect correlation. This is similar in concept to an r^2 score, but the calculation is slightly different - if the mean of the error terms is 0, then the explained variance is the same as r^2. [1]\n",
    "\n",
    "As can be seen here, this is 0.40 for the training data, and 0.32 for the test data, meaning that only a small amount of the variation in glucose levels can be predicted by our independent variables. This makes sense, as although diabetes status may have an effect, it is likely that the time since the patient last ate will have a much more significant effect on glucose levels. These are slightly different from our linear values, with a better performance on the training data, and a worse on the test data. The better performance on the test data for the linear model means that the linear model is likely better.\n",
    "\n",
    "Unfortunately, this value is just hard to predict from our independent variables, although estimates can be gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Explained Variance : 0.4041286112837972\n",
      "Test Explained Variance : 0.3220331751778678\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Explained Variance :\", explained_variance_score(training_y, y_pred))\n",
    "print(\"Test Explained Variance :\", explained_variance_score(test_y, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Regression on a Graph\n",
    "\n",
    "We can also attempt to visualise the regression, by plotting the curve. This can be done with mean values of other variables kept constant, as we vary one, and see the impact upon the dependent variable.\n",
    "\n",
    "As age is the 8th independent variable in the DataFrame, this is the one we vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#Determine the range of one of our variables, to be plotted\n",
    "print(np.max(df[\"Age\"]))\n",
    "print(np.min(df[\"Age\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   3.845052\n",
       "Glucose                     120.894531\n",
       "BloodPressure                69.105469\n",
       "SkinThickness                20.536458\n",
       "Insulin                      79.799479\n",
       "BMI                          31.992578\n",
       "DiabetesPedigreeFunction      0.471876\n",
       "Age                          33.240885\n",
       "Outcome                       0.348958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the mean values\n",
    "means = np.mean(df)\n",
    "\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e61674fe48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate space in age category\n",
    "x_space = np.linspace(21,80,100)\n",
    "\n",
    "#Create a DataFrame for our prediction points\n",
    "pred_df = pd.DataFrame({\"Pregnancies\": [means[0] for i in range(100)],\n",
    "                        \"BloodPressure\": [means[2] for i in range(100)],\n",
    "                        \"SkinThickness\": [means[3] for i in range(100)],\n",
    "                        \"Insulin\": [means[4] for i in range(100)],\n",
    "                        \"BMI\": [means[5] for i in range(100)],\n",
    "                        \"DiabetesPedigreeFunction\": [means[6] for i in range(100)],\n",
    "                        \"Age\" : x_space,\n",
    "                        \"Outcome\": [means[8] for i in range(100)]})\n",
    "\n",
    "pred_space = reg.predict(pred_df)\n",
    "\n",
    "#Plot Line\n",
    "plt.plot(x_space, pred_space, label=\"Degree = 2\")\n",
    "\n",
    "#Label axes\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Predicted Glucose Level\")\n",
    "plt.ylim(100, 150)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Weights (Coefficients) \n",
    "\n",
    "We can still view the weights of our model, albeit in a more involved way because of the pipeline. However, due to the polynomial regression, it becomes more difficult to understand which weight corresponds to which feature. This can be done iteratively, with the following code, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: x0, Weight: -1.1251478340342358\n",
      "Feature: x1, Weight: -0.2956838545465935\n",
      "Feature: x2, Weight: -0.3288325336311151\n",
      "Feature: x3, Weight: 0.2701809571658627\n",
      "Feature: x4, Weight: 0.9934723495365727\n",
      "Feature: x5, Weight: -42.35468558614904\n",
      "Feature: x6, Weight: 1.0429615895731745\n",
      "Feature: x7, Weight: 12.523729510271394\n",
      "Feature: x0^2, Weight: -0.06871345560660418\n",
      "Feature: x0 x1, Weight: 0.008503897532720994\n",
      "Feature: x0 x2, Weight: -9.920351580417261e-05\n",
      "Feature: x0 x3, Weight: -0.0045217232639874925\n",
      "Feature: x0 x4, Weight: 0.025326628785087697\n",
      "Feature: x0 x5, Weight: -0.032494745390785944\n",
      "Feature: x0 x6, Weight: 0.016941828504340065\n",
      "Feature: x0 x7, Weight: -0.09731941651365666\n",
      "Feature: x1^2, Weight: 0.004692646578054917\n",
      "Feature: x1 x2, Weight: 0.006424569326820701\n",
      "Feature: x1 x3, Weight: -0.00190454783362365\n",
      "Feature: x1 x4, Weight: 0.0008549535522616623\n",
      "Feature: x1 x5, Weight: 0.3262564890679345\n",
      "Feature: x1 x6, Weight: -0.0061049868717649265\n",
      "Feature: x1 x7, Weight: -0.09776949866229549\n",
      "Feature: x2^2, Weight: 0.010387730156535843\n",
      "Feature: x2 x3, Weight: 0.0009215481095996845\n",
      "Feature: x2 x4, Weight: -0.03190280145259204\n",
      "Feature: x2 x5, Weight: -0.08207088481876745\n",
      "Feature: x2 x6, Weight: 0.004949700480737628\n",
      "Feature: x2 x7, Weight: 0.12135108667119371\n",
      "Feature: x3^2, Weight: -9.620673281755422e-05\n",
      "Feature: x3 x4, Weight: 0.0004371869152970262\n",
      "Feature: x3 x5, Weight: -0.0034960232814652877\n",
      "Feature: x3 x6, Weight: -9.741056753997945e-06\n",
      "Feature: x3 x7, Weight: -0.02973017827812703\n",
      "Feature: x4^2, Weight: 0.0017410637643299962\n",
      "Feature: x4 x5, Weight: 0.4736495901191637\n",
      "Feature: x4 x6, Weight: -0.02522858343675677\n",
      "Feature: x4 x7, Weight: 0.2823720077982238\n",
      "Feature: x5^2, Weight: 13.417436715317873\n",
      "Feature: x5 x6, Weight: -0.455785551092903\n",
      "Feature: x5 x7, Weight: -2.138947265270032\n",
      "Feature: x6^2, Weight: 0.008560732207742311\n",
      "Feature: x6 x7, Weight: -0.06447460268293279\n",
      "Feature: x7^2, Weight: 12.52372951107829\n",
      "Intercept: 70.7557480585524\n"
     ]
    }
   ],
   "source": [
    "#Extract weights and names from the model\n",
    "weights = reg.steps[1][1].coef_\n",
    "names = reg.steps[0][1].get_feature_names()\n",
    "\n",
    "#Print out the feature names and corresponding weights\n",
    "for i in range(len(weights)-1):\n",
    "    \n",
    "    #Find the corresponding weight\n",
    "    weight = weights[i+1]\n",
    "    name = names[i+1]\n",
    "    \n",
    "    print(f\"Feature: {name}, Weight: {weight}\")\n",
    "\n",
    "#Print Intercept\n",
    "intercept = reg.steps[1][1].intercept_\n",
    "print(f\"Intercept: {intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The glucose level for any known $X_0$ through $X_7$ value can therefore be estimated. Remember from above that the first column in the DataFrame referred to the number of pregnancies, so this is variable $X_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "To make further use of the model, we can predict new dependent variable values. This can be done with any measured independent variable values.\n",
    "\n",
    "Here, we choose mean values for each, and see what the prediction for this is. This prediction is 112.6, which is slightly different from the linear regression prediction of 121, and although the units are not given with the dataset, we can assume this to be a standard g/L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                  3.845052\n",
       "BloodPressure               69.105469\n",
       "SkinThickness               20.536458\n",
       "Insulin                     79.799479\n",
       "BMI                         31.992578\n",
       "DiabetesPedigreeFunction     0.471876\n",
       "Age                         33.240885\n",
       "Outcome                      0.348958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.mean(df.drop([\"Glucose\"], axis=1))\n",
    "\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112.63221035])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making an example prediction\n",
    "\n",
    "#Our example point will be at the mean all dependent variables\n",
    "\n",
    "#Predict y value - means is first changed to a numpy array and then reshaped to fit the function\n",
    "predicted_y = reg.predict(np.array(means).reshape(1, -1))\n",
    "\n",
    "predicted_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Things that I've referenced go here, to be cleaned up later\n",
    "\n",
    "- [1] https://stats.stackexchange.com/questions/210168/what-is-the-difference-between-r2-and-variance-score-in-scikit-learn\n",
    "- SciKit-Learn\n",
    "- Numpy\n",
    "- Kaggle dataset\n",
    "- Multicollinearity source - https://towardsdatascience.com/multi-collinearity-in-regression-fe7a2c1467ea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
