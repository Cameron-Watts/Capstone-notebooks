{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours Classification of Heart Disease\n",
    "\n",
    "Data downloaded from the UCI Machine Learning Repository at https://archive.ics.uci.edu/ml/datasets/heart+Disease\n",
    "\n",
    "Original data seen from Kaggle at https://www.kaggle.com/ronitf/heart-disease-uci. This data is edited and is incorrect, so is not used.\n",
    "\n",
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import packages\n",
    "\n",
    "#Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Finding the data on our system\n",
    "import pathlib\n",
    "\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Cross-validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Splitting data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Metrics to evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Plotting library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Dataset\n",
    "\n",
    "When you collect your own data, you should know exactly what each of the variables represent, and how the variables are encoded. Unfortunately, when working with others' data, we don't start with a full understanding of the data. Not being able to understand the data makes it extremely difficult to gain insight from it. You should definitely document any data of your own, as you might have to come back to it later, or someone else might have to interpret it in the future.\n",
    "\n",
    "As it turns out with the original dataset that was planned to be used in this example ([Kaggle Heart Disease UCI](https://www.kaggle.com/ronitf/heart-disease-uci)), it is also important to check the integrity of the dataset, especially if we plan to use the insights that we extract from the data. Resulting from investigation of the data, it seems that this source has edited data, and is misleading in various areas (for example, the indicator variable values for heart disease were swapped!). Therefore, we swap to using a correct version of the dataset, cited by multiple papers using this: [UCI Machine Learning Repository Heart Disease Dataset](https://archive.ics.uci.edu/ml/datasets/heart+Disease). This illustrates just how important it is to be able to trust our datasets if we're planning to use them.\n",
    "\n",
    "At the UCI Machine Learning Repository, there is an accurate description of every column, of which only 14 are used (we will keep with this convention and only use these columns). The description of these columns is given as follows, to help our understanding:\n",
    "\n",
    "\n",
    "- age: age in years\n",
    "- sex: sex (1 = male; 0 = female)\n",
    "- cp: chest pain type\n",
    "1. Value 1: typical angina\n",
    "2. Value 2: atypical angina\n",
    "3. Value 3: non-anginal pain\n",
    "4. Value 4: asymptomatic\n",
    "- trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "- chol: serum cholestoral in mg/dl\n",
    "- fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "- restecg: resting electrocardiographic results\n",
    "0. Value 0: normal\n",
    "1. Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "2. Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "- thalach: maximum heart rate achieved\n",
    "- exang: exercise induced angina (1 = yes; 0 = no)\n",
    "- oldpeak = ST depression induced by exercise relative to rest\n",
    "- slope: the slope of the peak exercise ST segment\n",
    "1. Value 1: upsloping\n",
    "2. Value 2: flat\n",
    "3. Value 3: downsloping\n",
    "- ca: number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "- num: diagnosis of heart disease (angiographic disease status)\n",
    "0. Value 0: < 50% diameter narrowing (No disease)\n",
    "1. Value 1-4: > 50% diameter narrowing (Disease)\n",
    "\n",
    "The \"num\" variable is used as our target value, and as described in the description of the dataset, non-zero values here indicate disease. Therefore, we can later transform our dataset to have either a 0, or a 1 for any disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data from the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Import data from another directory\n",
    "\n",
    "#Define the columns as described\n",
    "cols = [\n",
    "    \"age\",\n",
    "    \"sex\",\n",
    "    \"cp\",\n",
    "    \"trestbps\",\n",
    "    \"chol\",\n",
    "    \"fbs\",\n",
    "    \"restecg\",\n",
    "    \"thalach\",\n",
    "    \"exang\",\n",
    "    \"oldpeak\",\n",
    "    \"slope\",\n",
    "    \"ca\",\n",
    "    \"thal\",\n",
    "    \"num\"\n",
    "]\n",
    "\n",
    "\n",
    "#Find the file from a local directiory\n",
    "p = str(pathlib.Path().resolve()).replace(\"\\\\Notebooks\\\\Classification Methods\", \"\")\n",
    "p += (\"\\\\Data\\\\Raw\\\\Heart_Disease_UCI.csv\")\n",
    "p = pathlib.Path(p).resolve()\n",
    "\n",
    "#Read into a pandas dataframe\n",
    "df = pd.read_csv(p, names=cols)\n",
    "\n",
    "#Preview the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    float64\n",
      " 1   sex       303 non-null    float64\n",
      " 2   cp        303 non-null    float64\n",
      " 3   trestbps  303 non-null    float64\n",
      " 4   chol      303 non-null    float64\n",
      " 5   fbs       303 non-null    float64\n",
      " 6   restecg   303 non-null    float64\n",
      " 7   thalach   303 non-null    float64\n",
      " 8   exang     303 non-null    float64\n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    float64\n",
      " 11  ca        303 non-null    object \n",
      " 12  thal      303 non-null    object \n",
      " 13  num       303 non-null    int64  \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Display basic information about the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the target variable \"num\" into an indicator variable\n",
    "df[\"num\"] = [0 if i == 0 else 1 for i in df[\"num\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have a few weird values in the dataset, such as this one. We can't use these datapoints for our analysis, and there are only a couple of them, so we will drop these rows. From our call of `df.info()`, we can see that these are in the \"ca\" and \"thal\" columns (because the data-type is object, meaning anything can occupy the position, rather than float64, specifying a decimal number), so we remove rows containing non-numeric values in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show weird value\n",
    "df[\"thal\"][266]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 297 entries, 0 to 301\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       297 non-null    float64\n",
      " 1   sex       297 non-null    float64\n",
      " 2   cp        297 non-null    float64\n",
      " 3   trestbps  297 non-null    float64\n",
      " 4   chol      297 non-null    float64\n",
      " 5   fbs       297 non-null    float64\n",
      " 6   restecg   297 non-null    float64\n",
      " 7   thalach   297 non-null    float64\n",
      " 8   exang     297 non-null    float64\n",
      " 9   oldpeak   297 non-null    float64\n",
      " 10  slope     297 non-null    float64\n",
      " 11  ca        297 non-null    float64\n",
      " 12  thal      297 non-null    float64\n",
      " 13  num       297 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 34.8 KB\n"
     ]
    }
   ],
   "source": [
    "#Remove non-numeric datapoints\n",
    "df = df[pd.to_numeric(df[\"ca\"], errors='coerce').notnull()]\n",
    "df = df[pd.to_numeric(df[\"thal\"], errors='coerce').notnull()]\n",
    "\n",
    "#Change columns to numeric\n",
    "df[\"ca\"] = pd.to_numeric(df[\"ca\"])\n",
    "df[\"thal\"] = pd.to_numeric(df[\"thal\"])\n",
    "\n",
    "#Show our summary again, to check if our conversion worked\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "\n",
    "The data that we have has several categorical variables, which, although represented numerically, do need to be encoded. These variables have more than 2 categories that datapoints are fit into (those with 2 categories are already effectively encoded), which includes:\n",
    "- cp\n",
    "- restecg\n",
    "- slope\n",
    "- thal\n",
    "- ca\n",
    "\n",
    "We one-hot encode these using a built-in Pandas function `pd.get_dummies()`. We don't yet add these variables back into the DataFrame because of the scaling step that we will perform later, that is not appropriate for categorical variables such as these. Later, we will reconstruct a full DataFrame, such that we can train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex  trestbps   chol  fbs  thalach  exang  oldpeak  num\n",
       "0    63.0  1.0     145.0  233.0  1.0    150.0    0.0      2.3    0\n",
       "1    67.0  1.0     160.0  286.0  0.0    108.0    1.0      1.5    1\n",
       "2    67.0  1.0     120.0  229.0  0.0    129.0    1.0      2.6    1\n",
       "3    37.0  1.0     130.0  250.0  0.0    187.0    0.0      3.5    0\n",
       "4    41.0  0.0     130.0  204.0  0.0    172.0    0.0      1.4    0\n",
       "..    ...  ...       ...    ...  ...      ...    ...      ...  ...\n",
       "297  57.0  0.0     140.0  241.0  0.0    123.0    1.0      0.2    1\n",
       "298  45.0  1.0     110.0  264.0  0.0    132.0    0.0      1.2    1\n",
       "299  68.0  1.0     144.0  193.0  1.0    141.0    0.0      3.4    1\n",
       "300  57.0  1.0     130.0  131.0  0.0    115.0    1.0      1.2    1\n",
       "301  57.0  0.0     130.0  236.0  0.0    174.0    0.0      0.0    1\n",
       "\n",
       "[297 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-hot encoding\n",
    "cp_dummies = pd.get_dummies(df[\"cp\"], prefix=\"cp\")\n",
    "restecg_dummies = pd.get_dummies(df[\"restecg\"], prefix=\"restecg\")\n",
    "slope_dummies = pd.get_dummies(df[\"slope\"], prefix=\"slope\")\n",
    "thal_dummies = pd.get_dummies(df[\"thal\"], prefix=\"thal\")\n",
    "ca_dummies = pd.get_dummies(df[\"ca\"], prefix=\"ca\")\n",
    "\n",
    "#Drop the original variables from the DataFrame\n",
    "df = df.drop([\"cp\", \"restecg\", \"slope\", \"thal\", \"ca\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling with StandardScaler\n",
    "\n",
    "After removing the rest of the categorical variables, the next step in the process is to scale the data appropriately, so we don't give bias towards smaller variables in the machine learning. For example, if this dataset had chosen to measure cholesterol in mg/L instead of mg/dl, the measurements would be very small. In terms of nearest-neighbours, this would mean that the nearest neighbour would almost always have to be very close in this measurement, and variables with larger spread would be ignored, such as age.\n",
    "\n",
    "Because of this, we rescale the data, transforming it such that every variable has a mean of 0, and a standard deviation of 1. We do however keep the relative distance between the variables, keeping our measurements relative, but unitless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the remaining categorical variables to be added later\n",
    "\n",
    "cat_variables = df[[\"sex\", \"fbs\", \"exang\"]]\n",
    "y = df[\"num\"]\n",
    "\n",
    "df = df.drop([\"sex\", \"fbs\", \"exang\", \"num\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  trestbps   chol  thalach  oldpeak\n",
       "0  63.0     145.0  233.0    150.0      2.3\n",
       "1  67.0     160.0  286.0    108.0      1.5\n",
       "2  67.0     120.0  229.0    129.0      2.6\n",
       "3  37.0     130.0  250.0    187.0      3.5\n",
       "4  41.0     130.0  204.0    172.0      1.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936181</td>\n",
       "      <td>0.750380</td>\n",
       "      <td>-0.276443</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>1.068965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.378929</td>\n",
       "      <td>1.596266</td>\n",
       "      <td>0.744555</td>\n",
       "      <td>-1.816334</td>\n",
       "      <td>0.381773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.378929</td>\n",
       "      <td>-0.659431</td>\n",
       "      <td>-0.353500</td>\n",
       "      <td>-0.899420</td>\n",
       "      <td>1.326662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.941680</td>\n",
       "      <td>-0.095506</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>1.633010</td>\n",
       "      <td>2.099753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.498933</td>\n",
       "      <td>-0.095506</td>\n",
       "      <td>-0.835103</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.295874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  trestbps      chol   thalach   oldpeak\n",
       "0  0.936181  0.750380 -0.276443  0.017494  1.068965\n",
       "1  1.378929  1.596266  0.744555 -1.816334  0.381773\n",
       "2  1.378929 -0.659431 -0.353500 -0.899420  1.326662\n",
       "3 -1.941680 -0.095506  0.051047  1.633010  2.099753\n",
       "4 -1.498933 -0.095506 -0.835103  0.978071  0.295874"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the remaining variables\n",
    "\n",
    "#Create the scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit the scaler to our dataset, then transform the data\n",
    "df = scaler.fit_transform(df)\n",
    "\n",
    "#The scaler outputs a numpy array, so we need to make it back into a DataFrame\n",
    "# Note here the argument \"names\" from pd.read_csv becomes \"columns\"\n",
    "df = pd.DataFrame(df, columns = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.970000e+02</td>\n",
       "      <td>2.970000e+02</td>\n",
       "      <td>2.970000e+02</td>\n",
       "      <td>2.970000e+02</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.226105e-16</td>\n",
       "      <td>4.904420e-16</td>\n",
       "      <td>-1.958777e-16</td>\n",
       "      <td>4.784800e-16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001688e+00</td>\n",
       "      <td>1.001688e+00</td>\n",
       "      <td>1.001688e+00</td>\n",
       "      <td>1.001688e+00</td>\n",
       "      <td>1.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.827176e+00</td>\n",
       "      <td>-2.125634e+00</td>\n",
       "      <td>-2.337704e+00</td>\n",
       "      <td>-3.431849e+00</td>\n",
       "      <td>-0.906712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.241238e-01</td>\n",
       "      <td>-6.594306e-01</td>\n",
       "      <td>-7.002541e-01</td>\n",
       "      <td>-7.247694e-01</td>\n",
       "      <td>-0.906712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.613719e-01</td>\n",
       "      <td>-9.550637e-02</td>\n",
       "      <td>-8.380217e-02</td>\n",
       "      <td>1.484822e-01</td>\n",
       "      <td>-0.219520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.148067e-01</td>\n",
       "      <td>4.684179e-01</td>\n",
       "      <td>5.519138e-01</td>\n",
       "      <td>7.160957e-01</td>\n",
       "      <td>0.467672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.485798e+00</td>\n",
       "      <td>3.851964e+00</td>\n",
       "      <td>6.099981e+00</td>\n",
       "      <td>2.287949e+00</td>\n",
       "      <td>4.419026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age      trestbps          chol       thalach     oldpeak\n",
       "count  2.970000e+02  2.970000e+02  2.970000e+02  2.970000e+02  297.000000\n",
       "mean  -1.226105e-16  4.904420e-16 -1.958777e-16  4.784800e-16    0.000000\n",
       "std    1.001688e+00  1.001688e+00  1.001688e+00  1.001688e+00    1.001688\n",
       "min   -2.827176e+00 -2.125634e+00 -2.337704e+00 -3.431849e+00   -0.906712\n",
       "25%   -7.241238e-01 -6.594306e-01 -7.002541e-01 -7.247694e-01   -0.906712\n",
       "50%    1.613719e-01 -9.550637e-02 -8.380217e-02  1.484822e-01   -0.219520\n",
       "75%    7.148067e-01  4.684179e-01  5.519138e-01  7.160957e-01    0.467672\n",
       "max    2.485798e+00  3.851964e+00  6.099981e+00  2.287949e+00    4.419026"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show that the scaling worked!\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombine Data\n",
    "\n",
    "Here, we recombine the data back into a single DataFrame (exlcuding the target/dependent variable \"num\"), such that we can fit our model to it later.\n",
    "\n",
    "Unfortunately, after performing opertaions on the separate DataFrames, the indexes become off, such that we have to reset these for the data to realign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset all indexes\n",
    "df = df.reset_index()\n",
    "cat_variables = cat_variables.reset_index()\n",
    "cp_dummies = cp_dummies.reset_index()\n",
    "restecg_dummies = restecg_dummies.reset_index()\n",
    "slope_dummies = slope_dummies.reset_index()\n",
    "thal_dummies = thal_dummies.reset_index()\n",
    "ca_dummies = ca_dummies.reset_index()\n",
    "\n",
    "#Recombine all sources of data back into a singular DataFrame object\n",
    "df = pd.concat([df, \n",
    "                cat_variables, \n",
    "                cp_dummies, \n",
    "                restecg_dummies, \n",
    "                slope_dummies, \n",
    "                thal_dummies,\n",
    "                ca_dummies], ignore_index=False, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>index</th>\n",
       "      <th>sex</th>\n",
       "      <th>fbs</th>\n",
       "      <th>exang</th>\n",
       "      <th>...</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>index</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>index</th>\n",
       "      <th>ca_0.0</th>\n",
       "      <th>ca_1.0</th>\n",
       "      <th>ca_2.0</th>\n",
       "      <th>ca_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.936181</td>\n",
       "      <td>0.750380</td>\n",
       "      <td>-0.276443</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>1.068965</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.378929</td>\n",
       "      <td>1.596266</td>\n",
       "      <td>0.744555</td>\n",
       "      <td>-1.816334</td>\n",
       "      <td>0.381773</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.378929</td>\n",
       "      <td>-0.659431</td>\n",
       "      <td>-0.353500</td>\n",
       "      <td>-0.899420</td>\n",
       "      <td>1.326662</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.941680</td>\n",
       "      <td>-0.095506</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>1.633010</td>\n",
       "      <td>2.099753</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.498933</td>\n",
       "      <td>-0.095506</td>\n",
       "      <td>-0.835103</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.295874</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       age  trestbps      chol   thalach   oldpeak  index  sex  fbs  \\\n",
       "0      0  0.936181  0.750380 -0.276443  0.017494  1.068965      0  1.0  1.0   \n",
       "1      1  1.378929  1.596266  0.744555 -1.816334  0.381773      1  1.0  0.0   \n",
       "2      2  1.378929 -0.659431 -0.353500 -0.899420  1.326662      2  1.0  0.0   \n",
       "3      3 -1.941680 -0.095506  0.051047  1.633010  2.099753      3  1.0  0.0   \n",
       "4      4 -1.498933 -0.095506 -0.835103  0.978071  0.295874      4  0.0  0.0   \n",
       "\n",
       "   exang  ...  slope_3.0  index  thal_3.0  thal_6.0  thal_7.0  index  ca_0.0  \\\n",
       "0    0.0  ...          1      0         0         1         0      0       1   \n",
       "1    1.0  ...          0      1         1         0         0      1       0   \n",
       "2    1.0  ...          0      2         0         0         1      2       0   \n",
       "3    0.0  ...          1      3         1         0         0      3       1   \n",
       "4    0.0  ...          0      4         1         0         0      4       1   \n",
       "\n",
       "   ca_1.0  ca_2.0  ca_3.0  \n",
       "0       0       0       0  \n",
       "1       0       0       1  \n",
       "2       0       1       0  \n",
       "3       0       0       0  \n",
       "4       0       0       0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train Split\n",
    "\n",
    "A vital part of machine learning is being able to test with data that the model is not trained on. This means that we can test the generalisability of our model with this data. We use SciKit-Learn's train_test_split in order to take 20% of the data at random to be test data. This method keeps the associated dependent variable values with each row of the independent variables, and also randomises the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Training\n",
    "\n",
    "Here, we train our KNN model to classify the data. After this, we can test this on the test data, to see how well it does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Search Cross Validation\n",
    "\n",
    "To avoid over-fitting to our data, and to choose a good value of K for KNN, we use a technique called cross-validation. This involves splitting our data into several \"folds\" (a given fraction of the data). We then choose a value of K to test, and train our data on all but one of these folds. The remaining fold is tested upon, to get a test-data accuracy score. We repeat this with each one of the folds being left out, and get an average test-data score, without using the real test data! This process is completed for each value of K that we want to test, and we take the value that scored the best on our defined metric (this time we'll use accuracy).\n",
    "\n",
    "We can do this automatically with Scikit-Learn's GridSearchCV. Here, we search through ranges from K=1 to K=10 (remember that ranges in Python are non-inclusive at the top-end), to see which gives us the best performance. Before running this, we likely expect a value of K=2 or K=3 to appear best, as this doesn't take only the nearest point into consideration, which might be too sensitive. We also don't expect K=10 to be the best, as this takes a lot of points into account, and might miss some \"areas\" of classification that don't have a lot of samples in them.\n",
    "\n",
    "More than one parameter can be changed through a grid search, but be warned that we're creating many more possibilities to check when doing so. For example, currently we test 10 different values of K, but if we wanted to test another parameter across 10 possible values too, we would suddenly have 100 possible combinations to check. You can see how this might quickly scale for more complicated implementations, where we test 1000s of possible combinations on huge datasets. This is why the absolute best machine learning implementations require such huge computational power!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-nearest neighbours object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Define the parameters that we want to test for\n",
    "parameters = {\"n_neighbors\": list(range(1,11))}\n",
    "\n",
    "#Define the grid-search\n",
    "clf = GridSearchCV(knn, parameters)\n",
    "\n",
    "#Fit the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the best parameter for this model\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we expected, the best value for k is 3 for this dataset. Luckily, we don't even have to retrain our model with this knowledge, as we can just predict directly with the grid-search model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Data\n",
    "\n",
    "Finally, we can predict against test-data to evaluate the usefulness of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict against test and training data\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7890295358649789"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score for training data\n",
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score for training data\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
